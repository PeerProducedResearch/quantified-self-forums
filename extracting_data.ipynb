{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "moved-third",
   "metadata": {},
   "source": [
    "## Quantified Self Forum analysis\n",
    "###  Extracting data by category: \n",
    "<ul>\n",
    "<li><a href=\"#posts_cat\">Posts by category</a></li>\n",
    "<li> <a  href=\"#qs\">  QS category </a></li>\n",
    "<li><a href=\"#unc\">UNC category</a></li>\n",
    "<li><a href=\"#meta\">Meta category</a></li>\n",
    "<li><a href=\"#admin\">Admin category</a></li>\n",
    "<li><a href=\"#user_list\">User List </a></li>\n",
    "</ul>\n",
    "\n",
    "###  Creating Dataframe: \n",
    "<ul>\n",
    "<li><a href=\"#df\">Dataframe</a></li>\n",
    "<li><a href=\"#df_comments\">df comments</a></li>\n",
    "<li><a href=\"#df_posts\">df posts</a></li>\n",
    "<li><a href=\"#df_list\">df list</a></li>\n",
    "<li><a href=\"#df_global\">global df</a></li>\n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dominican-planner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.parse\n",
    "import requests\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-worthy",
   "metadata": {},
   "source": [
    "### function to extract nested data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-serve",
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_extract(obj, key):\n",
    "    \"\"\"Recursively fetch values from nested JSON.\"\"\"\n",
    "    arr = []\n",
    "\n",
    "    def extract(obj, arr, key):\n",
    "        \"\"\"Recursively search for values of key in JSON tree.\"\"\"\n",
    "        if isinstance(obj, dict):\n",
    "            for k, v in obj.items():\n",
    "                if isinstance(v, (dict, list)):\n",
    "                    extract(v, arr, key)\n",
    "                elif k == key:\n",
    "                    arr.append(v)\n",
    "        elif isinstance(obj, list):\n",
    "            for item in obj:\n",
    "                extract(item, arr, key)\n",
    "        return arr\n",
    "\n",
    "    values = extract(obj, arr, key)\n",
    "    return values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chronic-dinner",
   "metadata": {},
   "source": [
    "<a id='posts_cat'></a>\n",
    "\n",
    "## POSTS BY CATEGORY "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "responsible-journey",
   "metadata": {},
   "source": [
    "<a id='qs'></a>\n",
    "### 1 - Category : Quantified Self ----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-canon",
   "metadata": {},
   "source": [
    "#### I* overview posts + getting post id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subsequent-locator",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pages = np.arange(0, 71)\n",
    "\n",
    "with open('all_posts.json', 'w') as posts:\n",
    "    \n",
    "    all_posts = []   \n",
    "    for page in pages:    \n",
    "        page = requests.get(\"https://forum.quantifiedself.com/c/quantified-self/5.json?page=\" + str(page)).json()\n",
    "        all_posts.append(page)\n",
    "        \n",
    "    json.dump(all_posts, posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-suggestion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting <topic id> to get full posts\n",
    "\n",
    "mylist_n = [] \n",
    "\n",
    "def openposts(): \n",
    "    with open(\"all_posts.json\", 'r') as j:\n",
    "         content = json.load(j)\n",
    "    for page in content:\n",
    "        ids = json_extract(page[\"topic_list\"], 'id')\n",
    "        for ID in ids:\n",
    "            mylist_n.append(ID)     \n",
    "openposts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-belief",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking nested list\n",
    "len(mylist_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smaller-elimination",
   "metadata": {},
   "source": [
    "#### II* Quantified Self Full posts + comment ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-lexington",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting all full posts of QS category   \n",
    "     \n",
    "for index, ID in enumerate(mylist_n): \n",
    "    post = requests.get(\"https://forum.quantifiedself.com/t/\" + (str(ID)) + \".json\")\n",
    "    post = post.json()\n",
    "    with open('as_post' + str(index) + '.json', 'w') as file:\n",
    "         json.dump(post, file)\n",
    "            \n",
    "# iterating to get all comment ids in each post\n",
    "    \n",
    "    with open('comment_ids.txt', 'a') as comment_ids:\n",
    "            for comment in post[\"post_stream\"][\"stream\"]: \n",
    "                comment_ids.write(str(comment)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "killing-spelling",
   "metadata": {},
   "source": [
    "#### III* Getting all comments of each post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-financing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# unpacking list of ids numbers\n",
    "\n",
    "with open('comment_ids.txt', 'r') as c:\n",
    "    thread_id = c.read().splitlines()\n",
    "results = list(map(int, thread_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-dayton",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, ID in enumerate(results):\n",
    "        comment = requests.get(\"https://forum.quantifiedself.com/posts/\" + str(ID) + \".json\")\n",
    "        comment = comment.json()\n",
    "        with open('comment' + str(index) + '.json', 'w') as threads:\n",
    "            json.dump(comment, threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-crime",
   "metadata": {},
   "source": [
    "<a id='unc'></a>\n",
    "\n",
    "### 2- Catgory : Uncategorized  ----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-optimization",
   "metadata": {},
   "source": [
    "#### I* overview posts + getting post id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-steps",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = np.arange(0, 8)\n",
    "\n",
    "with open('UNC_posts.json', 'w') as all_posts:\n",
    "    \n",
    "    UNC_posts = []\n",
    "    for page in pages:    \n",
    "        page = requests.get(\"https://forum.quantifiedself.com/c/uncategorized/1.json?page=\" + str(page)).json()\n",
    "        UNC_posts.append(page)\n",
    "        \n",
    "    json.dump(UNC_posts, all_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-birmingham",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting <topic id> to get full posts\n",
    "\n",
    "mylist_n = [] \n",
    "\n",
    "def open_posts(): \n",
    "    with open(\"UNC_posts.json\", 'r') as j:\n",
    "         content = json.load(j)\n",
    "    for page in content:\n",
    "        ids = json_extract(page[\"topic_list\"], 'id')\n",
    "        for ID in ids:\n",
    "            mylist_n.append(ID)     \n",
    "open_posts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-child",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mylist_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-second",
   "metadata": {},
   "source": [
    "#### II* Uncategorized Full posts + comment ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-collect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting all full posts of QS category   \n",
    "     \n",
    "for index, ID in enumerate(mylist_n): \n",
    "    post0 = requests.get(\"https://forum.quantifiedself.com/t/\" + (str(ID)) + \".json\")\n",
    "    post0 = post0.json()\n",
    "    with open('unc_post' + str(index) + '.json', 'w') as f:\n",
    "         json.dump(post0, f)\n",
    "            \n",
    "# iterating to get all comment ids in each post\n",
    "    \n",
    "    with open('comment_idz.txt', 'a') as comment_idz:\n",
    "            for commentt in post0[\"post_stream\"][\"stream\"]: \n",
    "                comment_idz.write(str(commentt)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-point",
   "metadata": {},
   "source": [
    "#### III* Getting all comments of each post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-obligation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking list of ids numbers\n",
    "\n",
    "with open('comment_idz.txt', 'r') as z:\n",
    "    thread_idz = z.read().splitlines()\n",
    "result = list(map(int, thread_idz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-restaurant",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, ID in enumerate(result):\n",
    "        comment0 = requests.get(\"https://forum.quantifiedself.com/posts/\" + str(ID) + \".json\")\n",
    "        comment0 = comment0.json()\n",
    "        with open('unc_comment' + str(index) + '.json', 'w') as threadz:\n",
    "            json.dump(comment0, threadz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-phenomenon",
   "metadata": {},
   "source": [
    "<a id='meta'></a>\n",
    "\n",
    "### 3- Catgory : META  ----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-invitation",
   "metadata": {},
   "source": [
    "#### I* overview posts + getting post id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-technology",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = np.arange(0, 1)\n",
    "\n",
    "with open('META_posts.json', 'w') as all_postz:\n",
    "    \n",
    "    meta_ids= []\n",
    "    for page in pages:    \n",
    "        page = requests.get(\"https://forum.quantifiedself.com/c/meta/3.json?page=\" + str(page)).json()\n",
    "        meta_ids.append(page)\n",
    "        \n",
    "    json.dump(meta_ids, all_postz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-sierra",
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist_n = [] \n",
    "\n",
    "def openposts(): \n",
    "    with open(\"META_posts.json\", 'r') as j:\n",
    "         content = json.load(j)\n",
    "    for page in content:\n",
    "        ids = json_extract(page[\"topic_list\"], 'id')\n",
    "        for ID in ids:\n",
    "            mylist_n.append(ID)     \n",
    "openposts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-eagle",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mylist_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catholic-coffee",
   "metadata": {},
   "source": [
    "#### II* Meta Full posts + comment ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-arctic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting all full posts of QS category   \n",
    "     \n",
    "for index, ID in enumerate(mylist_n): \n",
    "    post0 = requests.get(\"https://forum.quantifiedself.com/t/\" + (str(ID)) + \".json\")\n",
    "    post0 = post0.json()\n",
    "    with open('meta_post' + str(index) + '.json', 'w') as f:\n",
    "         json.dump(post0, f)\n",
    "            \n",
    "# iterating to get all comment ids in each post\n",
    "    \n",
    "    with open('m_comment_idz.txt', 'a') as comment_idz:\n",
    "            for commentt in post0[\"post_stream\"][\"stream\"]: \n",
    "                comment_idz.write(str(commentt)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-sarah",
   "metadata": {},
   "source": [
    "#### III* Getting all comments of each post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instant-frederick",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking list of ids numbers\n",
    "\n",
    "with open('m_comment_idz.txt', 'r') as z:\n",
    "    thread_idz = z.read().splitlines()\n",
    "result = list(map(int, thread_idz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-ladder",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, ID in enumerate(result):\n",
    "        comment0 = requests.get(\"https://forum.quantifiedself.com/posts/\" + str(ID) + \".json\")\n",
    "        comment0 = comment0.json()\n",
    "        with open('meta_comment' + str(index) + '.json', 'w') as threadz:\n",
    "            json.dump(comment0, threadz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latest-dynamics",
   "metadata": {},
   "source": [
    "<a id='admin'></a>\n",
    "\n",
    "### 4- Catgory : QS Admin  ----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-tampa",
   "metadata": {},
   "source": [
    "#### I* overview posts + getting post id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-albuquerque",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = np.arange(0, 1)\n",
    "\n",
    "with open('Admin_posts.json', 'w') as all_postz:\n",
    "    \n",
    "    admin_ids= []\n",
    "    for page in pages:    \n",
    "        page = requests.get(\"https://forum.quantifiedself.com/c/qs-admin/6.json?page=\" + str(page)).json()\n",
    "        admin_ids.append(page)\n",
    "        \n",
    "    json.dump(admin_ids, all_postz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-victor",
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist_n = [] \n",
    "\n",
    "def openposts(): \n",
    "    with open(\"Admin_posts.json\", 'r') as j:\n",
    "         content = json.load(j)\n",
    "    for page in content:\n",
    "        ids = json_extract(page[\"topic_list\"], 'id')\n",
    "        for ID in ids:\n",
    "            mylist_n.append(ID)     \n",
    "openposts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-cleaner",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(mylist_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-force",
   "metadata": {},
   "source": [
    "#### II* Admin Full posts + comment ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-cornwall",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting all full posts of QS category   \n",
    "     \n",
    "for index, ID in enumerate(mylist_a): \n",
    "    post0 = requests.get(\"https://forum.quantifiedself.com/t/\" + (str(ID)) + \".json\")\n",
    "    post0 = post0.json()\n",
    "    with open('ad_post' + str(index) + '.json', 'w') as f:\n",
    "         json.dump(post0, f)\n",
    "            \n",
    "# iterating to get all comment ids in each post\n",
    "    \n",
    "    with open('acomment_idz.txt', 'a') as comment_idz:\n",
    "            for commentt in post0[\"post_stream\"][\"stream\"]: \n",
    "                comment_idz.write(str(commentt)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-channel",
   "metadata": {},
   "source": [
    "#### III* Getting all comments of each post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-stack",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking list of ids numbers\n",
    "\n",
    "with open('acomment_idz.txt', 'r') as z:\n",
    "    thread_idz = z.read().splitlines()\n",
    "result = list(map(int, thread_idz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-fitness",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, ID in enumerate(result):\n",
    "        comment0 = requests.get(\"https://forum.quantifiedself.com/posts/\" + str(ID) + \".json\")\n",
    "        comment0 = comment0.json()\n",
    "        with open('ad_comment' + str(index) + '.json', 'w') as threadz:\n",
    "            json.dump(comment0, threadz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-frequency",
   "metadata": {},
   "source": [
    "<a id='user_list'></a>\n",
    "\n",
    "## USERS LIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "level-seattle",
   "metadata": {},
   "source": [
    "- total_rows_directory_items\t5696\n",
    "- 113 pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-quantity",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_num = np.arange(0, 114)\n",
    "\n",
    "for index, ID in enumerate(page_num): \n",
    "    post = requests.get(\"https://forum.quantifiedself.com/directory_items.json?page=\" + (str(ID)) + \"&period=all\")\n",
    "    post = post.json()\n",
    "    with open('user_page' + str(index) + '.json', 'w') as file:\n",
    "         json.dump(post, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-triple",
   "metadata": {},
   "source": [
    "<a id='df'></a>\n",
    "# Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-princeton",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folderpath = r\"/Users/kaoutarlanjri/a_Quantified_Self_Project/1_C_category/QS_posts\"\n",
    "filepaths  = [os.path.join(folderpath, name) for name in os.listdir(folderpath)]\n",
    "all_files = []\n",
    "\n",
    "for path in filepaths:\n",
    "    with open(path, 'r') as f:\n",
    "        file = f.read()\n",
    "        #all_files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-constraint",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "a_dict = collections.defaultdict(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-implement",
   "metadata": {},
   "source": [
    "### Test with one post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-integration",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "dataFolder = Path(r'/Users/kaoutarlanjri/a_Quantified_Self_Project/1_C_category/QS_comments/comment0.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-least",
   "metadata": {},
   "outputs": [],
   "source": [
    "def openposts(): \n",
    "    with open(dataFolder, 'r') as j:\n",
    "         post = json.load(j)\n",
    "    df = pd.DataFrame.from_dict(post, orient=\"index\")\n",
    "    df_tr = df.transpose()\n",
    "    return df_tr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-lindsay",
   "metadata": {},
   "source": [
    "# -------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominican-latest",
   "metadata": {},
   "source": [
    "<a id='df_comments'></a>\n",
    "# 1 - Comments df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-chapter",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = '/Users/kaoutarlanjri/a_Quantified_Self_Project/1_C_category/QS_comments/'\n",
    "json_data = []\n",
    "\n",
    "def extract_comments():\n",
    "    \n",
    "    for filename in glob.glob(os.path.join(path, '*.json')):     \n",
    "\n",
    "        with open(filename, encoding='utf-8', mode='r') as currentFile:\n",
    "            content = json.load(currentFile)\n",
    "            json_data.append(content)\n",
    "            \n",
    "extract_comments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-gender",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.DataFrame.from_records(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-thriller",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-vertex",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv('raw_comments.csv', header = True, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "impaired-counter",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv('raw_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-feeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-caribbean",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "asian-certification",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments = df_all[['id', 'username', 'user_id', 'created_at', 'cooked', 'post_number', 'updated_at', 'reply_count',\n",
    "           'reply_to_user','reply_to_post_number', 'quote_count', 'incoming_link_count', 'reads', 'readers_count', 'topic_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "serious-sense",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>username</th>\n",
       "      <th>user_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>cooked</th>\n",
       "      <th>post_number</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>reply_to_user</th>\n",
       "      <th>reply_to_post_number</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>incoming_link_count</th>\n",
       "      <th>reads</th>\n",
       "      <th>readers_count</th>\n",
       "      <th>topic_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6997</td>\n",
       "      <td>QuantifiedBob</td>\n",
       "      <td>884</td>\n",
       "      <td>2016-03-14T17:40:17.744Z</td>\n",
       "      <td>&lt;p&gt;The size of the mask plus electronics is ra...</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-03-14T17:40:42.276Z</td>\n",
       "      <td>1</td>\n",
       "      <td>{'username': 'Dan_Dascalescu', 'avatar_templat...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>2139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id       username  user_id                created_at  \\\n",
       "0  6997  QuantifiedBob      884  2016-03-14T17:40:17.744Z   \n",
       "\n",
       "                                              cooked  post_number  \\\n",
       "0  <p>The size of the mask plus electronics is ra...            3   \n",
       "\n",
       "                 updated_at  reply_count  \\\n",
       "0  2016-03-14T17:40:42.276Z            1   \n",
       "\n",
       "                                       reply_to_user  reply_to_post_number  \\\n",
       "0  {'username': 'Dan_Dascalescu', 'avatar_templat...                   2.0   \n",
       "\n",
       "   quote_count  incoming_link_count  reads  readers_count  topic_id  \n",
       "0            0                   10     31             30      2139  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comments.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-craft",
   "metadata": {},
   "source": [
    "### Exporting to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "provincial-vatican",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments.to_csv('comments.csv', header = True, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "elect-optics",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments = pd.read_csv('comments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sporting-breeding",
   "metadata": {},
   "source": [
    "### * Creating 1st network df from comments df and extracting username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "valued-associate",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1513"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_df_1 = df_comments[[\"created_at\", \"username\",\"reply_to_user\"]]\n",
    "network_df_1 = network_df_1.dropna()\n",
    "len(network_df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "positive-marketplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert str col to dict type\n",
    "network_df_1[\"reply_to_user\"] = network_df_1.reply_to_user.apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "willing-teens",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_df_1[\"reply_to_user\"] = network_df_1[\"reply_to_user\"].apply(lambda keys: keys.get('username'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "understood-waters",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>username</th>\n",
       "      <th>reply_to_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-03-14T17:40:17.744Z</td>\n",
       "      <td>QuantifiedBob</td>\n",
       "      <td>Dan_Dascalescu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 created_at       username   reply_to_user\n",
       "0  2016-03-14T17:40:17.744Z  QuantifiedBob  Dan_Dascalescu"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_df_1.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-there",
   "metadata": {},
   "source": [
    "<a id='df_posts'></a>\n",
    "# 2 - Posts df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "prescription-anthropology",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/kaoutarlanjri/a_Quantified_Self_Project/1_C_category/QS_posts/'\n",
    "data = []\n",
    "\n",
    "def extract_posts():\n",
    "\n",
    "    for filename in glob.glob(os.path.join(path, '*.json')):     \n",
    "\n",
    "        with open(filename, encoding='utf-8', mode='r') as currentFile:\n",
    "            post = json.load(currentFile)\n",
    "            data.append(post)\n",
    "            \n",
    "extract_posts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "general-nursing",
   "metadata": {},
   "source": [
    "#### extracting posts datasets  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-laser",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_posts = []\n",
    "in_posts = []\n",
    "\n",
    "for i in data: #info outside post stream\n",
    "    \n",
    "    out_posts.append([i['id'], #rename to topic_id\n",
    "                      i['post_stream']['stream'], i['tags'], \n",
    "                      i['title'], i['posts_count'], i['views'], i['like_count'], i['closed'],\n",
    "                      i['category_id'], i['word_count'], i['featured_link']\n",
    "                    ])\n",
    "    \n",
    "    for j in i['post_stream']['posts']: #info inside post stream\n",
    "        \n",
    "        in_posts.append([\n",
    "                         j['id'], j['username'], j['user_id'], j['created_at'] ,j['updated_at'], \n",
    "                         j['cooked'], j['post_number'], j['reply_count'],j['reply_to_post_number'], \n",
    "                         j['quote_count'],j['incoming_link_count'],j['reads'],j['readers_count'],\n",
    "                         j['topic_id'], j.get('reply_to_user')\n",
    "                        ])\n",
    "\n",
    "    \n",
    "in_posts_df = pd.DataFrame(data=in_posts, columns=['id', 'username', 'user_id', 'created_at', 'updated_at', \n",
    "                                                   'cooked', 'post_number','reply_count', 'reply_to_post_number', \n",
    "                                                   'quote_count', 'incoming_link_count','reads', 'readers_count', \n",
    "                                                   'topic_id','reply_to_user'])\n",
    "\n",
    "out_posts_df = pd.DataFrame(data=out_posts, columns=['topic_id', # id rename to 'topic_id'\n",
    "                                                    'stream', 'tags', 'title', 'posts_count','views',\n",
    "                                                    'like_count', 'closed', 'category_id', 'word_count',\n",
    "                                                    'featured_link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-giant",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "in_posts_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-function",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out_posts_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-receptor",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(len(out_posts_df))\n",
    "print(len(in_posts_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-energy",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_posts_df.to_csv('in_posts_df.csv', header = True, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fundamental-benefit",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_posts_df.to_csv('out_posts_df.csv', header = True, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "prostate-hands",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_posts_df = pd.read_csv('in_posts_df.csv')\n",
    "out_posts_df = pd.read_csv('out_posts_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "color-reducing",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>username</th>\n",
       "      <th>user_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>cooked</th>\n",
       "      <th>post_number</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>reply_to_post_number</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>incoming_link_count</th>\n",
       "      <th>reads</th>\n",
       "      <th>readers_count</th>\n",
       "      <th>topic_id</th>\n",
       "      <th>reply_to_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16418</td>\n",
       "      <td>fermion</td>\n",
       "      <td>8713</td>\n",
       "      <td>2019-07-24T09:24:11.337Z</td>\n",
       "      <td>2019-07-30T18:35:39.494Z</td>\n",
       "      <td>&lt;p&gt;First: Thanks to all developers and to all ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>7139</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id username  user_id                created_at  \\\n",
       "0  16418  fermion     8713  2019-07-24T09:24:11.337Z   \n",
       "\n",
       "                 updated_at  \\\n",
       "0  2019-07-30T18:35:39.494Z   \n",
       "\n",
       "                                              cooked  post_number  \\\n",
       "0  <p>First: Thanks to all developers and to all ...            1   \n",
       "\n",
       "   reply_count  reply_to_post_number  quote_count  incoming_link_count  reads  \\\n",
       "0            0                   NaN            0                   11     14   \n",
       "\n",
       "   readers_count  topic_id reply_to_user  \n",
       "0             13      7139           NaN  "
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_posts_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-sodium",
   "metadata": {},
   "source": [
    "### * Creating 2nd network df from comments df and extracting username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "invalid-study",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1301"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_df_2 = in_posts_df[[\"created_at\", \"username\",\"reply_to_user\"]]\n",
    "network_df_2 = network_df_2.dropna()\n",
    "len(network_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "incident-discretion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert str col to dict type\n",
    "network_df_2[\"reply_to_user\"] = network_df_2.reply_to_user.apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "major-biodiversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_df_2[\"reply_to_user\"] = network_df_2[\"reply_to_user\"].apply(lambda keys: keys.get('username'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "earlier-guess",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>username</th>\n",
       "      <th>reply_to_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07-25T23:21:56.518Z</td>\n",
       "      <td>fermion</td>\n",
       "      <td>Steven_Jonas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 created_at username reply_to_user\n",
       "2  2019-07-25T23:21:56.518Z  fermion  Steven_Jonas"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_df_2.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-method",
   "metadata": {},
   "source": [
    "## Social Network df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "average-bacteria",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>username</th>\n",
       "      <th>reply_to_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-03-14T17:40:17.744Z</td>\n",
       "      <td>QuantifiedBob</td>\n",
       "      <td>Dan_Dascalescu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-12-16T19:25:20.064Z</td>\n",
       "      <td>Krishnan</td>\n",
       "      <td>Patrik_Helenius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-08-30T02:43:01.551Z</td>\n",
       "      <td>ankoshy</td>\n",
       "      <td>ejain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-09-08T07:59:23.531Z</td>\n",
       "      <td>markwkoester</td>\n",
       "      <td>Eremolalos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-02T13:10:47.375Z</td>\n",
       "      <td>cfuarte</td>\n",
       "      <td>ejain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 created_at       username    reply_to_user\n",
       "0  2016-03-14T17:40:17.744Z  QuantifiedBob   Dan_Dascalescu\n",
       "1  2016-12-16T19:25:20.064Z       Krishnan  Patrik_Helenius\n",
       "2  2016-08-30T02:43:01.551Z        ankoshy            ejain\n",
       "3  2017-09-08T07:59:23.531Z   markwkoester       Eremolalos\n",
       "4  2019-07-02T13:10:47.375Z        cfuarte            ejain"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_df = network_df_1.merge(network_df_2, how='left')\n",
    "network_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "engaged-treat",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_df.to_csv('network_df.csv', header = True, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-silver",
   "metadata": {},
   "source": [
    "### Merging posts df with comment df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-affect",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_comments.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-nothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_posts_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-garbage",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(in_posts_df))\n",
    "print(len(in_posts_df.user_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-outside",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(df_comments))\n",
    "print(len(df_comments.user_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-struggle",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df_comments.merge(in_posts_df, how='left')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-transcription",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-prisoner",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df.user_id.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completed-revelation",
   "metadata": {},
   "source": [
    "### Merging all posts df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-conservative",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_posts = df.merge(out_posts_df, how='left', on=('topic_id'))\n",
    "df_posts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-liability",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-visibility",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(df_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-folks",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_posts.user_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-librarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts.to_csv('dt_posts_comments.csv', header = True, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-daughter",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts = pd.read_csv('dt_posts_comments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-climate",
   "metadata": {},
   "source": [
    "<a id='df_list'></a>\n",
    "# 3 - Userlist df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acute-target",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/kaoutarlanjri/a_Quantified_Self_Project/5_USER_list'\n",
    "userlist = []\n",
    "\n",
    "def extract_userlist():\n",
    "    for filename in glob.glob(os.path.join(path, '*.json')):     \n",
    "\n",
    "        with open(filename, encoding='utf-8', mode='r') as currentFile:\n",
    "            post = json.load(currentFile)\n",
    "            userlist.append(post)\n",
    "            \n",
    "extract_userlist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "pleasant-principle",
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist = []\n",
    "file_num = 0\n",
    "\n",
    "for i in userlist:\n",
    "    for j in i['directory_items']: \n",
    "    \n",
    "        mylist.append([ j['id'], j['time_read'],j['likes_received'], j['likes_given'], j['topics_entered'],\n",
    "                        j['topic_count'], j['post_count'], j['posts_read'], j['days_visited'],\n",
    "                        j['user']['username'], j['user']['name'] \n",
    "                      ])\n",
    "        \n",
    "    file_num+=1\n",
    "\n",
    "userlist_df = pd.DataFrame(data=mylist, columns=['user_id', 'time_read', 'likes_received', 'likes_given', 'topics_entered',\n",
    "                                             'topic_count', 'post_count', 'posts_read', 'days_visited', 'username', 'name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "automotive-northeast",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>time_read</th>\n",
       "      <th>likes_received</th>\n",
       "      <th>likes_given</th>\n",
       "      <th>topics_entered</th>\n",
       "      <th>topic_count</th>\n",
       "      <th>post_count</th>\n",
       "      <th>posts_read</th>\n",
       "      <th>days_visited</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9591</td>\n",
       "      <td>760</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>Sakamoto</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  time_read  likes_received  likes_given  topics_entered  \\\n",
       "0     9591        760               0            0               7   \n",
       "\n",
       "   topic_count  post_count  posts_read  days_visited  username  name  \n",
       "0            0           0          44             1  Sakamoto  None  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userlist_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "prostate-burlington",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'time_read', 'likes_received', 'likes_given',\n",
       "       'topics_entered', 'topic_count', 'post_count', 'posts_read',\n",
       "       'days_visited', 'username', 'name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userlist_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "simple-afghanistan",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5696"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(userlist_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "married-injection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4336\n"
     ]
    }
   ],
   "source": [
    "print(len(userlist_df.user_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-native",
   "metadata": {},
   "outputs": [],
   "source": [
    "userlist_df['user_id'] = userlist_df['user_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adapted-preference",
   "metadata": {},
   "outputs": [],
   "source": [
    "userlist_df.to_csv('userlist.csv', header = True, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "convertible-saskatchewan",
   "metadata": {},
   "outputs": [],
   "source": [
    "userlist_df = pd.read_csv('userlist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "weighted-montgomery",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4336\n"
     ]
    }
   ],
   "source": [
    "print(len(userlist_df.user_id.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "treated-baseline",
   "metadata": {},
   "source": [
    "### Recap:\n",
    "   * **userlist_df** =  (users list df)\n",
    "   * **df_posts** =   (posts+comment df)\n",
    "   * **global_df** =  (allposts+users df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "persistent-breathing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user dataset: 5696\n",
      "unique users: 4336\n"
     ]
    }
   ],
   "source": [
    "print('user dataset:', len(userlist_df))\n",
    "print('unique users:', len(userlist_df.user_id.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-treat",
   "metadata": {},
   "source": [
    "<a id='df_global'></a>\n",
    "# Global Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "outside-princeton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'user_id', 'created_at', 'cooked', 'post_number', 'updated_at',\n",
       "       'reply_count', 'reply_to_post_number', 'quote_count',\n",
       "       'incoming_link_count', 'reads', 'readers_count', 'topic_id',\n",
       "       'reply_to_user', 'stream', 'tags', 'title', 'posts_count', 'views',\n",
       "       'like_count', 'closed', 'category_id', 'word_count', 'featured_link',\n",
       "       'time_read', 'likes_received', 'likes_given', 'topics_entered',\n",
       "       'topic_count', 'post_count', 'posts_read', 'days_visited', 'username',\n",
       "       'name', '_merge'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_df = pd.merge(df_posts, userlist_df, how='outer',indicator=True, on ='user_id')\n",
    "global_df = global_df.drop([\"username_x\"], axis=1)\n",
    "global_df.rename(columns = {'username_y' : 'username'}, inplace = True)\n",
    "global_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "activated-local",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique users: 4377\n",
      "global df: 15244\n"
     ]
    }
   ],
   "source": [
    "print('unique users:', len(global_df.user_id.unique()))\n",
    "print('global df:', len(global_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "careful-firewall",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_df.to_csv('global_df.csv', header = True, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "useful-negotiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_df = pd.read_csv('global_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-remove",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_non_match = global_df[(global_df._merge != 'both')]\n",
    "global_non_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "friendly-boards",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique users: 4377\n",
      "global df: 15244\n"
     ]
    }
   ],
   "source": [
    "print('unique users:', len(global_df.user_id.unique()))\n",
    "print('global df:', len(global_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-minister",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_df['id'] = global_df['id'].astype(str)\n",
    "global_df['post_number'] = global_df['post_number'].astype(str)\n",
    "global_df['reply_to_post_number'] = global_df['reply_to_post_number'].astype(str)\n",
    "global_df['topic_id'] = global_df['topic_id'].astype(str)\n",
    "global_df['user_id'] = global_df['user_id'].astype(str)\n",
    "global_df['category_id'] = global_df['category_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-assistant",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_df.to_csv('global_df.csv', header = True, encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
